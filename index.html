<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Diff-Control: A Stateful Diffusion-based Policy for Imitation Learning">
  <meta name="keywords" content="Diffusion Model, Imitation Learning, Stateful Policy">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Diff-Control: A Stateful Diffusion-based Policy for Imitation Learning</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/irl_lab.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://diff-control.github.io/">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <!-- <a class="navbar-item" href="https://github.com/ir-lab/DEnKF">
              Differentiable Ensemble Kalman Filter (DEnKF)
            </a>
            <a class="navbar-item" href="https://github.com/ir-lab/soft_robot_DEnKF">
              DEnKF + soft robot and spatio-temporal embedding
            </a> -->
            <!-- <a class="navbar-item" href="https://latentfusion.github.io">
              LatentFusion
            </a>
            <a class="navbar-item" href="https://photoshape.github.io">
              PhotoShape
            </a> -->
          </div>
        </div>
      </div>

    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Diff-Control: A Stateful Diffusion-based Policy for Imitation
              Learning</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://www.xiao-liu.me/">Xiao Liu</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="http://yifanzhou.com/">Yifan Zhou</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://faweigend.com/">Fabian Weigend </a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.sdsonawani.com/">Shubham Sonawani</a> <sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.brain.kyutech.ac.jp/~ikemoto/people.html">Shuhei Ikemoto</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="http://henibenamor.weebly.com/">Heni Ben Amor</a><sup>1</sup>,
              </span>
              <!-- <span class="author-block">
                <a href="https://www.danbgoldman.com">Dan B Goldman</a><sup>2</sup>,
              </span> -->
              <!-- <span class="author-block">
                <a href="https://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                <a href="http://www.ricardomartinbrualla.com">Ricardo Martin-Brualla</a><sup>2</sup>
              </span> -->
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup><a
                  href="https://interactive-robotics.engineering.asu.edu/">Interactive Robotics Lab, Arizona State
                  University</span></a>
              <span class="author-block"><sup>2</sup><a href="https://www.brain.kyutech.ac.jp/~ikemoto/"> Kyushu
                  Institute of Technology</span></a>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="./static/videos/Diff-Control.pdf" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/2011.12948" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span> -->
                <!-- Video Link. -->
                <span class="link-block">
                  <a href="./static/videos/task_sequence.mp4" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/ir-lab/Diff-Control"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="https://www.dropbox.com/scl/fo/2onj92s7gewettu1rjg3d/h?rlkey=1d4dnhwf3z6s4a51lopgocby5&dl=0"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">

        <!-- <img src="./static/videos/teaser.png" class="interpolation-image" alt="Interpolate start reference image." /> -->

        <video id="teaser" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/task_sequence.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">

          <strong>Diff-Control Policy</strong> incorporates ControlNet, functioning as a transition model that captures
          temporal transitions within the action space to ensure action consistency.

        </h2>
      </div>
    </div>
  </section>


  <!-- <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-steve">
            <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/steve.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp">
            <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/chair-tp.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-shiba">
            <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/shiba.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-fullbody">
            <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/fullbody.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-blueshirt">
            <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/blueshirt.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-mask">
            <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/mask.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-coffee">
            <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/coffee.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-toby">
            <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/toby2.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section> -->


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              While imitation learning provides a simple and effective framework for policy learning, acquiring
              consistent action during robot execution remains a challenging task. Existing approaches primarily focus
              on either modifying the action representation at data curation stage or altering the model itself, both of
              which do not fully address the scalability of consistent action generation. To overcome this limitation,
              we introduce the <strong>Diff-Control</strong> policy, which utilizes a diffusion-based model to learn
              action representation from a state-space modeling viewpoint. We demonstrate that diffusion-based policies
              can acquire statefulness through a Bayesian formulation facilitated by ControlNet, leading to improved
              robustness and success rates. Our experimental results demonstrate the significance of incorporating
              action statefulness in policy learning, where Diff-Control shows improved performance across various
              tasks. Specifically, Diff-Control achieves an average success rate of 72% and 84% on stateful and
              dynamic tasks, respectively. Notably, Diff-Control also shows consistent performance in the presence of
              perturbations, outperforming other state-of-the-art methods that falter under similar conditions.
            </p>
            <!-- <p>
              We show that <span class="dnerf">Nerfies</span> can turn casually captured selfie
              photos/videos into deformable NeRF
              models that allow for photorealistic renderings of the subject from arbitrary
              viewpoints, which we dub <i>"nerfies"</i>. We evaluate our method by collecting data
              using a
              rig with two mobile phones that take time-synchronized photos, yielding train/validation
              images of the same pose at different viewpoints. We show that our method faithfully
              reconstructs non-rigidly deforming scenes and reproduces unseen views with high
              fidelity.
            </p> -->
          </div>
        </div>
      </div>
      <!--/ Abstract. -->



      <!-- Paper video. -->
      <!-- <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/OdBMquRUTdU" frameborder="0" allow="autoplay; encrypted-media"
              allowfullscreen></iframe>
          </div>
        </div>
      </div> -->
      <!--/ Paper video. -->
    </div>
  </section>




  <section class="section">
    <div class="container is-max-desktop">

      <!--/ method. -->
      <div class="columns is-centered has-text-centered">
        <!-- Regid Body motion -->
        <div class="column">
          <div class="content">
            <h2 class="title is-3">Language-Conditioned</h2>
            <p>
              Among all the baseline methods, Diff-Control achieves the highest success rate with 92%, which is 5%,
              64%, and 32% higher than diffusion policy, ModAttn, and Image-BC, respectively.
            </p>
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/tomato_fuse.mp4" type="video/mp4">
            </video>
          </div>
        </div>
        <!--/ Regid Body motion -->

        <!-- Soft robot motion -->
        <div class="column">
          <div class="content">
            <h2 class="title is-3">High-Precision</h2>
            <p>
              Diff-Control policy is able to achieve this high-precision task with 80% success rate over 25 trials,
              Diff-Control policy demonstrated superior performance and does not show the tendency to overfit on idle
              actions.
            </p>
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/Open_lid.mp4" type="video/mp4">
            </video>
          </div>
        </div>
        <!--/ soft robot motion -->
      </div>
      <!--/ Matting. -->


      <!--/ method. -->
      <div class="columns is-centered has-text-centered">
        <!-- Regid Body motion -->
        <div class="column">
          <div class="content">
            <h2 class="title is-3">Dynamic Environment</h2>
            <p>
              Diff-Control policy achieves a commendable success rate of 84% while performing in this dynamic task.
              It demonstrates a tendency to scoop the duck out in a single
              attempt, reaching a low enough position for accurate scooping.
            </p>
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/duck.mp4" type="video/mp4">
            </video>
          </div>
        </div>
        <!--/ Regid Body motion -->

        <!-- Soft robot motion -->
        <div class="column">
          <div class="content">
            <h2 class="title is-3">Periodic Motion</h2>
            <p>
              Diff-Control achieves the highest success rate of 72%, it is able to predict the direction of actions
              correctly (upward or downward) and knows when to halt the actions. The stateful behavior is beneficial for
              robot learning periodic motions.
            </p>
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/drum.mp4" type="video/mp4">
            </video>
          </div>
        </div>
        <!--/ soft robot motion -->
      </div>
      <!--/ Matting. -->



      <!-- method. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Diff-Control Policy</h2>

          <!-- Interpolating. -->
          <h3 class="title is-4">Overview</h3>
          <div class="content has-text-justified">
            <p>
              The key objective of Diff-Control is to learn how to incorporate state information into the
              decision-making process of diffusion policies. In computer vision, ControlNet is used within stable
              diffusion models to enable additional control inputs or extra conditions when generating images or video
              sequences. Our method extends the basic principle of ControlNet from image generation to action
              generation, and use it as a state-space model in which the internal state of the system affects the output
              of the policy in conjunction with observations (camera input) and human language instructions.
            </p>
            <img src="./static/videos/controlnet.png" class="interpolation-image"
              alt="Interpolate start reference image." />
            <p>
              Diff-Control operates by generating a sequence of actions while incorporating conditioning on previously
              generated actions. In this example, the Diff-Control policy is depicted executing the "Open Lid" task. For
              instance, in the second sub-figure,
              the blue trajectory represents previous action trajectory, denoted as
              <strong>a<sub>[W<sub>t</sub>]</sub></strong>, while
              the red trajectory
              displays the newly generated sequence of actions, denoted as
              <strong>a<sub>[W<sub>t-h</sub>]</sub></strong>.
            </p>
          </div>


          <!-- Attention Gain -->
          <h3 class="title is-4">Stateful behavior</h3>
          <div class="content has-text-justified">
            <p>
              We find that proposed Diff-Control policy effectively maintains stateful behavior by conditioning its
              actions on prior actions, resulting in consistent action generation. An illustrative example for this
              behavior is shown below: a policy learning to approximate a cosine function. Given single observation at
              time t, stateless policies encounter difficulties in producing accurate generating the continuation of
              trajectories. Due to ambiguities, diffusion policy tends to learn multiple modes. By contrast,
              Diff-Control integrates temporal conditioning allowing it to generate trajectories by considering past
              states. To this end, the proposed approach leverages recent ControlNet architectures to ensure temporal
              consistency in robot action generation.
            </p>
            <center><img src="./static/videos/sine.png" width="600" height="500"></center>
            <p>
              At a given state, Diff-Control policy can utilize prior trajectories to approximate the desired function.
              Diffusion policy learns both modes but fails on generating the correct trajectory cosistently,
              Image-BC/BC-Z fails to generate the correct trajectory.
            </p>
          </div>
          <!--/ Attention Gain -->


          <!-- result -->
          <h3 class="title is-4">Tasks</h3>
          <div class="content has-text-justified">
            <p>
            <ul>
              <li><strong>Language Conditioned kitchen tasks</strong>: This task is designed to resemble several tasks
                in the kitchen scenario. </li>
              <li><strong>Open Lid task</strong>: this task is in the kitchen scene with a high-precision requirement.
              </li>
              <li><strong>Duck Scooping task</strong>: we explore the interaction between the policy and fluid dynamics.
              </li>
              <li><strong>Drum Beats (3 hits) task</strong>: this task is specifically designed for robots to learn
                periodic
                motions</li>
            </ul>

            </p>
            <img src="./static/videos/task.png" class="interpolation-image" alt="Interpolate start reference image." />
          </div>
          <!--/ result -->

          <!-- result -->
          <h3 class="title is-4">Evaluations</h3>
          <div class="content has-text-justified">
            <p>
            <ul>
              <li><strong>Image-BC</strong>: This baseline adopts an image-to-action agent
                framework, similar to BC-Z, it is built upon ResNet-18 backbone and employs FiLM for conditioning using
                CLIP language features. </li>
              <li><strong>ModAttn</strong>: This method employs a transformer-style neural network and uses a modular
                structure to address each sub-aspects of the task via neural attention, it requires a human expert
                correctly identifies components and subtasks to each task.
              </li>
              <li><strong>BC-Z LSTM</strong>: This baseline represents a stateful policy inspired by the BC-Z
                architecture. The incorporation of a prior input is achieved by fusing the prior actions and language
                conditions using MLP and LSTM layers.
              </li>
              <li><strong>Diffusion Policy</strong>: This baseline is a standard diffusion policy.</li>
            </ul>

            </p>
            <center><img src="./static/videos/Table.png" width="800" height="600" class="interpolation-image"
                alt="Interpolate start reference image." /></center>
          </div>
          <!--/ result -->

        </div>
      </div>





      <!-- Concurrent Work. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Related Links</h2>

          <div class="content has-text-justified">
            <p>
              To assess the performance and effectiveness of our approach, we conducted comparative evaluations against
              robot learning policy baselines.
            </p>
            <p>
              <a href="https://diffusion-policy.cs.columbia.edu/">Diffusion Policy
              </a> serves as the base policy in proposed framework, similar design decisions has been made referring to
              the visual encodings, hyper-parameters, etc.
            </p>
            <p>
              We adapt <a href="https://github.com/lllyasviel/ControlNet">ControlNet</a> sturcture, expecially the zero
              convolusion layers to create Diff-Control in robot trajectory domain.
            </p>
            <p>
              Besides diffusion policy, we compared <a href="https://arxiv.org/abs/2202.02005">Image-BC/BC-Z</a>
              baseline, the <a href="https://arxiv.org/pdf/2212.04573.pdf">ModAttn</a> baseline, and BC-Z LSTM.
            </p>
          </div>
        </div>
      </div>
      <!--/ Concurrent Work. -->

    </div>
  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{liudiff,
        title={Diff-Control: A Stateful Diffusion-based Policy for Imitation Learning},
        author={Liu, Xiao and Zhou, Yifan and Weigend, Fabian and Sonawani, Shubham and Ikemoto, Shuhei and Amor, Heni Ben}
      }</code></pre>
      <pre><code>@article{liu2024enabling,
        title={Enabling Stateful Behaviors for Diffusion-based Policy Learning},
        author={Liu, Xiao and Weigend, Fabian and Zhou, Yifan and Amor, Heni Ben},
        journal={arXiv preprint arXiv:2404.12539},
        year={2024}
      }</code></pre>
    </div>



  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="./static/videos/Diff-Control.pdf">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/liuxiao1468" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              This means you are free to borrow the <a
                href="https://github.com/Diff-Control/Diff-Control.github.io">source
                code</a> of this website,
              we just ask that you link back to this page in the footer.
              Please remember to remove the analytics code included in the header of the website which
              you do not want on your website.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>